{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0d9c85-fffe-401d-bd77-7318b8937252",
   "metadata": {},
   "source": [
    "## Aluno: AndrÃ© de Souza Ferreira"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d944189-9e96-43ad-b8e5-acf603dbc496",
   "metadata": {},
   "source": [
    "### ImportaÃ§Ã£o do YOLOv5 e instalaÃ§Ã£o das dependÃªncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24917c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 15637, done.\u001b[K\n",
      "remote: Counting objects: 100% (244/244), done.\u001b[K\n",
      "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
      "remote: Total 15637 (delta 123), reused 173 (delta 100), pack-reused 15393\u001b[K\n",
      "Receiving objects: 100% (15637/15637), 14.58 MiB | 11.38 MiB/s, done.\n",
      "Resolving deltas: 100% (10652/10652), done.\n",
      "/home/asf/CESAR/dl-fruit-classification/yolov5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  \n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt \n",
    "%pip install -q roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79485ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import os\n",
    "from IPython.display import Image, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1bbded-ad78-4965-9008-4cb4a5ab969c",
   "metadata": {},
   "source": [
    "### InstalaÃ§Ã£o da biblioteca do Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3712cf1b-2b62-4b45-ba12-8475d5a4d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427680a6-cdd0-4558-8625-cff2f371de36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masf89\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb105fa-81c9-46e8-8c9e-9fc52595af42",
   "metadata": {},
   "source": [
    "### Download do dataset do Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b249ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (1.0.8)\n",
      "Requirement already satisfied: requests-toolbelt in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: certifi==2022.12.7 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: requests in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (2.30.0)\n",
      "Requirement already satisfied: python-dateutil in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: idna==2.10 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (1.24.3)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (1.26.15)\n",
      "Requirement already satisfied: six in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: chardet==4.0.0 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: wget in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (3.2)\n",
      "Requirement already satisfied: python-dotenv in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (4.7.0.72)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (9.5.0)\n",
      "Requirement already satisfied: matplotlib in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from roboflow) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from matplotlib->roboflow) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from matplotlib->roboflow) (23.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from matplotlib->roboflow) (4.39.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/asf/.local/share/virtualenvs/dl-fruit-classification-wIKk5y4h/lib/python3.10/site-packages (from requests->roboflow) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in Fruit-Types-1 to yolov5pytorch: 100% [15347626 / 15347626] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Fruit-Types-1 in yolov5pytorch:: 100%|â–ˆ| 612/612 [00:00<00:00, 13955.63it/\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"cT4klQDNb7TdLtLcsfJP\")\n",
    "project = rf.workspace(\"cesar-school-3vhz6\").project(\"fruit-types-aq9ue\")\n",
    "dataset = project.version(1).download(\"yolov5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cc262-6103-4fff-88dc-66d6d32cdae0",
   "metadata": {},
   "source": [
    "### Treinamento do modelo e apresentaÃ§Ã£o das mÃ©tricas por Ã©poca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a7056a-c9e5-400d-ba08-24288520bb85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masf89\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=27, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /home/asf/CESAR/dl-fruit-classification/requirements.txt not found, check failed.\n",
      "YOLOv5 ðŸš€ v7.0-162-gc3e4e94 Python-3.10.6 torch-2.0.0+cu117 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/asf/CESAR/dl-fruit-classification/yolov5/wandb/run-20230506_233857-vsbfopjy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlyric-haze-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/asf89/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/asf89/YOLOv5/runs/vsbfopjy\u001b[0m\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:00<00:00, 20.6MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.000421875), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/tra\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/train/labels.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:00<00:00, 1877.2\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/valid\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/valid/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:00<00:00, 1876.99it/\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.37 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Plotting labels to runs/train/exp/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/99         0G     0.1164    0.02865    0.04516         53        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING âš ï¸ NMS time limit 3.200s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING âš ï¸ NMS time limit 2.000s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84   0.000309     0.0646     0.0002   6.37e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/99         0G     0.1061    0.02819    0.04221         52        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING âš ï¸ NMS time limit 3.200s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING âš ï¸ NMS time limit 2.000s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84    0.00182      0.451    0.00966    0.00178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/99         0G    0.07826    0.02961     0.0376         41        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84    0.00369      0.952      0.206      0.069\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/99         0G    0.06001    0.02908    0.03203         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84     0.0381          1      0.448      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/99         0G     0.0569    0.02521     0.0361         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.507      0.724      0.752      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/99         0G    0.05547    0.02243    0.03416         40        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.675      0.799       0.98      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/99         0G    0.05748    0.01939    0.03041         46        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.805      0.265       0.42      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/99         0G    0.05392    0.01874    0.02469         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.393      0.724      0.712      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/99         0G    0.05796    0.01721    0.02546         41        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.451      0.658      0.662      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/99         0G    0.05739    0.01833    0.02054         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.471      0.825      0.734      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/99         0G    0.05328    0.01591    0.02335         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.648      0.912      0.878      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/99         0G    0.06263    0.01544    0.01662         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.666      0.926      0.729      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/99         0G     0.0592    0.01472    0.01638         53        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.581      0.917      0.707      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/99         0G    0.06015    0.01341    0.01401         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.791      0.983      0.928      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/99         0G    0.05354    0.01268    0.01574         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.546      0.789      0.608       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/99         0G    0.05424    0.01105   0.008662         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.433      0.915      0.629      0.266\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/99         0G    0.05971    0.01189    0.01095         40        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.547      0.924      0.853      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/99         0G    0.05077    0.01178    0.01044         53        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.712      0.904      0.861      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/99         0G    0.04519    0.01137   0.009303         46        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.462       0.95      0.825      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/99         0G    0.05215   0.009745   0.008352         48        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.507      0.978      0.922       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/99         0G    0.04896   0.009743   0.007397         41        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.377      0.971      0.691      0.328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/99         0G    0.05834   0.009947   0.006149         44        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.825      0.952      0.968      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/99         0G    0.05358   0.009512   0.007248         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.787      0.978      0.937       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/99         0G    0.04744    0.01061   0.006521         40        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.895        0.7      0.903      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/99         0G    0.05186    0.01077   0.007834         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.764      0.937      0.917      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/99         0G    0.03916   0.008841   0.005891         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.745      0.916      0.927      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/99         0G    0.04778    0.01078   0.006352         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.785      0.917      0.891      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/99         0G    0.04426   0.009191    0.00533         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.888       0.96      0.981      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/99         0G    0.04532   0.008635   0.007207         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.709          1      0.919      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/99         0G    0.04246   0.008149   0.006029         40        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.858      0.643      0.865      0.674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/99         0G      0.041   0.009422   0.006245         48        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.939      0.962      0.981      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/99         0G    0.03957   0.008634   0.004191         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.769      0.939      0.976      0.716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/99         0G     0.0395   0.008625   0.003282         46        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.872      0.992      0.941       0.64\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/99         0G    0.04042    0.00806   0.003379         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.949      0.948       0.97      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/99         0G    0.03828   0.008692   0.003797         32        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.796      0.952      0.938      0.725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/99         0G    0.03644    0.00794   0.006154         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.834      0.965      0.937      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/99         0G    0.03705   0.008637   0.006474         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.605          1      0.979      0.715\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/99         0G    0.03774   0.008382   0.006012         56        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.822      0.981      0.991      0.727\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/99         0G    0.03946   0.008283   0.005056         41        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.851      0.996      0.994       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/99         0G    0.04047   0.008023    0.01019         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.985          1      0.995      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/99         0G    0.03786   0.007725   0.003889         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84       0.85          1      0.985      0.685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/99         0G    0.03319    0.00748   0.005398         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.983          1      0.995      0.864\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/99         0G    0.03307   0.007172   0.004421         35        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.856          1      0.995      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/99         0G    0.03717   0.007269   0.003994         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.954          1      0.993       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/99         0G    0.04116   0.008095   0.006831         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.992          1      0.995      0.749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/99         0G    0.03333   0.007161    0.00287         40        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.984          1      0.995      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/99         0G    0.02835   0.007247    0.00457         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.896          1      0.995      0.707\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/99         0G    0.03728   0.007194   0.004385         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.959          1      0.995      0.755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/99         0G    0.03746   0.007951   0.007165         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.991      0.998      0.995      0.839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/99         0G     0.0295    0.00687   0.007014         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.989          1      0.995      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      50/99         0G    0.03438   0.007568   0.004476         44        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.986      0.998      0.995      0.825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      51/99         0G    0.02984   0.006485   0.004544         40        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84       0.96      0.993      0.995      0.894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      52/99         0G    0.03681   0.006895   0.003793         44        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.958      0.992      0.995       0.77\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      53/99         0G    0.02868   0.006433   0.005848         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.844      0.987      0.995      0.912\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      54/99         0G     0.0383   0.006939    0.00508         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.977      0.991      0.995      0.839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      55/99         0G    0.03043   0.007463   0.002906         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.937      0.992      0.994      0.776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      56/99         0G    0.03536   0.007067   0.005278         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.887      0.962      0.958      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      57/99         0G    0.02841   0.006787   0.002623         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.983      0.998      0.995       0.82\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      58/99         0G     0.0236   0.006943   0.002264         48        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.985      0.999      0.995      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      59/99         0G    0.03041   0.007039   0.002205         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.989          1      0.995      0.859\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      60/99         0G    0.02639   0.007144   0.001906         50        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.987      0.998      0.995      0.854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      61/99         0G    0.02619   0.007172   0.001964         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.992      0.992      0.995      0.859\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      62/99         0G    0.02696    0.00638   0.002354         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.988      0.998      0.995      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      63/99         0G    0.02404   0.007005   0.001917         57        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.992          1      0.995       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      64/99         0G    0.02856   0.006901    0.00365         44        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.992          1      0.995       0.89\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      65/99         0G    0.02425   0.006122   0.001496         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.992      0.999      0.995      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      66/99         0G    0.02604   0.006454   0.002103         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.992      0.999      0.995      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      67/99         0G    0.02532   0.006391   0.003128         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.994          1      0.995      0.863\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      68/99         0G    0.02309   0.006371   0.001656         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993      0.998      0.995      0.836\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      69/99         0G    0.02204   0.006817   0.002216         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.996          1      0.995      0.899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      70/99         0G    0.02197    0.00626   0.003096         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.872          1      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      71/99         0G    0.03333   0.006424   0.002214         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.872          1      0.995        0.9\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      72/99         0G    0.02426   0.006251   0.001757         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.996          1      0.995      0.908\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      73/99         0G    0.02355   0.006785    0.00231         41        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.996          1      0.995      0.861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      74/99         0G    0.02242   0.006272   0.009468         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.996          1      0.995      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      75/99         0G    0.02311   0.006403    0.00161         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      76/99         0G    0.02079   0.005867   0.002203         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.854\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      77/99         0G    0.02388   0.006094   0.002715         40        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.994          1      0.995      0.912\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      78/99         0G    0.02424   0.005737   0.002641         35        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.994          1      0.995      0.914\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      79/99         0G     0.0204   0.006512   0.001579         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      80/99         0G    0.02206   0.006071   0.001724         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995      0.896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      81/99         0G    0.02214   0.005884   0.002146         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995      0.908\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      82/99         0G    0.01985   0.006022   0.001777         32        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995      0.903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      83/99         0G    0.02489   0.005806   0.001837         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995      0.928\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      84/99         0G    0.01891   0.006303   0.001488         52        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995      0.905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      85/99         0G    0.02239   0.005932   0.002244         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      86/99         0G    0.01793   0.005807   0.001053         41        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995      0.918\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      87/99         0G    0.01622   0.006066   0.001194         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.993          1      0.995       0.92\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      88/99         0G    0.01846   0.005836   0.002583         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.994          1      0.995      0.918\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      89/99         0G    0.01776   0.006085   0.002251         46        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.994          1      0.995      0.931\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      90/99         0G    0.02067   0.005602   0.001201         53        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.994          1      0.995      0.923\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      91/99         0G    0.01883   0.005619   0.001502         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.994          1      0.995      0.905\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      92/99         0G    0.01822   0.005896   0.001223         48        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.994          1      0.995      0.931\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      93/99         0G    0.02073   0.005965   0.002607         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.927\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      94/99         0G    0.01838   0.006163   0.002801         57        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.923\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      95/99         0G    0.01786   0.006013   0.001189         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.919\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      96/99         0G    0.02047   0.005613   0.002663         52        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.934\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      97/99         0G    0.01286   0.005508   0.001029         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.931\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      98/99         0G    0.01915   0.005257   0.002006         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.933\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      99/99         0G    0.01435   0.005301  0.0007359         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.935\n",
      "\n",
      "100 epochs completed in 1.641 hours.\n",
      "Optimizer stripped from runs/train/exp/weights/last.pt, 14.5MB\n",
      "Optimizer stripped from runs/train/exp/weights/best.pt, 14.5MB\n",
      "\n",
      "Validating runs/train/exp/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         84         84      0.995          1      0.995      0.936\n",
      "               abacate         84         19      0.994          1      0.995       0.93\n",
      "                  kiwi         84         21      0.994          1      0.995      0.927\n",
      "                 mamao         84         26      0.998          1      0.995       0.93\n",
      "                 manga         84         18      0.993          1      0.995      0.956\n",
      "Results saved to \u001b[1mruns/train/exp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 â–â–‚â–ˆâ–†â–‡â–†â–…â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 â–â–‚â–…â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–„â–…â–…â–†â–…â–†â–…â–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision â–â–â–†â–„â–†â–…â–„â–†â–„â–‡â–†â–†â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall â–â–ˆâ–†â–†â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss â–ˆâ–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss â–ˆâ–‡â–†â–…â–…â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss â–ˆâ–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss â–ˆâ–„â–ƒâ–„â–ƒâ–†â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss â–ˆâ–†â–…â–„â–ƒâ–‚â–‚â–„â–â–â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss â–ˆâ–‡â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 â–â–‚â–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 â–â–‚â–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.93493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.99477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.93597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.99477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.00074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.00489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.00044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mlyric-haze-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/asf89/YOLOv5/runs/vsbfopjy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 15 media file(s), 3 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230506_233857-vsbfopjy/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --batch 27 --epochs 100 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092cb68-c256-4b07-8938-a4446397803c",
   "metadata": {},
   "source": [
    "### ValidaÃ§Ã£o do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7424aeda-a316-4a79-ad17-3e53bf772d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /home/asf/CESAR/dl-fruit-classification/requirements.txt not found, check failed.\n",
      "YOLOv5 ðŸš€ v7.0-162-gc3e4e94 Python-3.10.6 torch-2.0.0+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_28_jpg.rf.6b6cc2542cd6f7816a8668df1a6a18f0.jpg: 416x416 1 abacate, 38.6ms\n",
      "image 2/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_32_jpg.rf.53e22831f63445e4bd8507879797751b.jpg: 416x416 1 abacate, 33.6ms\n",
      "image 3/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_46_jpg.rf.e7bbe1feabff82c53f0451dc39dd4e05.jpg: 416x416 1 abacate, 35.0ms\n",
      "image 4/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_4_jpg.rf.72d49a448ae64af516bb736b482d16b8.jpg: 416x416 1 abacate, 32.4ms\n",
      "image 5/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_53_jpg.rf.84d53c42118afec4965978793616692a.jpg: 416x416 1 abacate, 31.4ms\n",
      "image 6/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_56_jpg.rf.dcc2e270b7f4288d1e68b675f3d75c60.jpg: 416x416 1 abacate, 34.2ms\n",
      "image 7/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_5_jpg.rf.2cb6c5b7a342de25e98f39c3d47eab75.jpg: 416x416 1 abacate, 34.8ms\n",
      "image 8/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_61_jpg.rf.e547d7a03b6114d70ecbe295d9d53519.jpg: 416x416 1 abacate, 31.5ms\n",
      "image 9/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_62_jpg.rf.5a7183721020f6cbc9842099c5503777.jpg: 416x416 1 abacate, 34.0ms\n",
      "image 10/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_68_jpg.rf.7ed743560d272ddfbed168ae8d7263b0.jpg: 416x416 1 abacate, 33.6ms\n",
      "image 11/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_72_jpg.rf.7f34a80abf0e440dcfe3aa45f7be8a08.jpg: 416x416 1 abacate, 35.1ms\n",
      "image 12/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/abacate_75_jpg.rf.05aa1033919f14975d28355b63524f36.jpg: 416x416 1 abacate, 33.6ms\n",
      "image 13/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_13_jpg.rf.5774b0fb89466c14220dd389435a1280.jpg: 416x416 1 kiwi, 35.2ms\n",
      "image 14/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_16_jpg.rf.271d1c90422fe6af8cfa3d8e8a3ce8d9.jpg: 416x416 1 kiwi, 30.3ms\n",
      "image 15/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_18_jpg.rf.c0d0c4684b1c6761452f040cc0fe715f.jpg: 416x416 1 kiwi, 32.6ms\n",
      "image 16/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_21_jpg.rf.bfbb048c90263a3359c2773b7cfc6f28.jpg: 416x416 1 kiwi, 32.0ms\n",
      "image 17/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_25_jpg.rf.066be4e3ae7119dc9a670786135abec9.jpg: 416x416 1 kiwi, 33.0ms\n",
      "image 18/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_38_jpg.rf.2f1c471edd781ee7094d5bc72f80f732.jpg: 416x416 1 kiwi, 34.2ms\n",
      "image 19/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_57_jpg.rf.a4691590cd4ada0698d7cd6614bf69b5.jpg: 416x416 1 kiwi, 32.5ms\n",
      "image 20/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_59_jpg.rf.db8ab259789826810005a7d68c89fc58.jpg: 416x416 1 kiwi, 30.9ms\n",
      "image 21/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_65_jpg.rf.9122f69712c6d3ea089e75930754c806.jpg: 416x416 1 kiwi, 33.4ms\n",
      "image 22/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_66_jpg.rf.d7e18ef76a4ecfc964c0ad5d8be4d5b0.jpg: 416x416 1 kiwi, 33.8ms\n",
      "image 23/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_72_jpg.rf.7208fda5b7851926708878594273b6db.jpg: 416x416 1 kiwi, 31.4ms\n",
      "image 24/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_74_jpg.rf.3cbdcbc864a09cbd1d213271f2f2d69f.jpg: 416x416 1 kiwi, 33.5ms\n",
      "image 25/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/kiwi_7_jpg.rf.4f934467cc2e03684e8e3f5e3bfa85a7.jpg: 416x416 1 kiwi, 35.7ms\n",
      "image 26/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_15_jpg.rf.49f3f523c5de4144729fca9db7b40951.jpg: 416x416 1 mamao, 33.6ms\n",
      "image 27/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_16_jpg.rf.a64754656bf37be7d20f25c9658aef47.jpg: 416x416 1 mamao, 28.9ms\n",
      "image 28/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_18_jpg.rf.2b78d9fdada702b32af6ef453708f779.jpg: 416x416 1 mamao, 24.2ms\n",
      "image 29/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_2_jpg.rf.af64cf69bbfee72e32f2aceabc5a58b1.jpg: 416x416 1 mamao, 42.4ms\n",
      "image 30/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_30_jpg.rf.a3c72a8dc68a2bdb467fba7072fe7ff7.jpg: 416x416 1 mamao, 32.8ms\n",
      "image 31/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_33_jpg.rf.440ea3937e7fe35d95e5da8fe7c2dd1f.jpg: 416x416 1 mamao, 32.3ms\n",
      "image 32/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_37_jpg.rf.734d3fd239466300a81666344fb2806a.jpg: 416x416 1 mamao, 34.1ms\n",
      "image 33/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_39_jpg.rf.b5c3a64fa1dbe84f164d67d5633551d1.jpg: 416x416 1 mamao, 32.3ms\n",
      "image 34/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_40_jpg.rf.47ed0b62feddba30f9f1adcda9664250.jpg: 416x416 1 mamao, 32.6ms\n",
      "image 35/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_44_jpg.rf.d46d218ee82578460950ba0d64c61486.jpg: 416x416 1 mamao, 32.1ms\n",
      "image 36/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_46_jpg.rf.7a2afc3ec22d79163a5b001f1c998200.jpg: 416x416 1 mamao, 33.6ms\n",
      "image 37/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_51_jpg.rf.dab429ea87842e32bc5ae850ec0257c0.jpg: 416x416 1 mamao, 33.7ms\n",
      "image 38/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_52_jpg.rf.d12cc6e52aa05c24cb0bfcdf4217b662.jpg: 416x416 1 mamao, 34.5ms\n",
      "image 39/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_53_jpg.rf.be595ea9765d5eddfc4d04a3de304637.jpg: 416x416 1 mamao, 30.7ms\n",
      "image 40/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_5_jpg.rf.77e2df63d00b55e2d7007c63ced94c30.jpg: 416x416 1 mamao, 32.9ms\n",
      "image 41/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_64_jpg.rf.e59a50b8c75254a712f63738d9f2a4f7.jpg: 416x416 1 mamao, 31.2ms\n",
      "image 42/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_65_jpg.rf.4861da8ca5b260f85f2e9e68f86aeed4.jpg: 416x416 1 mamao, 34.3ms\n",
      "image 43/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/mamao_72_jpg.rf.dff39604db9af98be89d653cfef4d3ea.jpg: 416x416 1 mamao, 30.1ms\n",
      "image 44/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_18_jpg.rf.1e17d2b85703625efc57ca71327f9702.jpg: 416x416 1 manga, 34.7ms\n",
      "image 45/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_1_jpg.rf.2c871649059298e0cbf6fcc038bad30f.jpg: 416x416 1 manga, 33.2ms\n",
      "image 46/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_20_jpg.rf.ab995ee1df017329f58959c07a5891f2.jpg: 416x416 1 manga, 32.7ms\n",
      "image 47/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_21_jpg.rf.3cc6e8a5a2bcc6fe9f6f7948aab29d6d.jpg: 416x416 1 manga, 31.2ms\n",
      "image 48/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_31_jpg.rf.56451e662ac08067b6c593469d489cb3.jpg: 416x416 1 manga, 28.0ms\n",
      "image 49/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_40_jpg.rf.99d17bdfc4b046c3a53c632ba248d1e3.jpg: 416x416 1 manga, 34.9ms\n",
      "image 50/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_45_jpg.rf.3e9eef1a3c4a964cc6b83d73f4d09fdb.jpg: 416x416 1 manga, 33.7ms\n",
      "image 51/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_49_jpg.rf.5361136bd3542d0a9fb0aba51f43ea71.jpg: 416x416 1 manga, 33.3ms\n",
      "image 52/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_50_jpg.rf.64e44ec4908fc0a5db0d0e18ddb022aa.jpg: 416x416 1 manga, 34.0ms\n",
      "image 53/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_54_jpg.rf.bd47e08d3a9b1b87dde771d2c7970791.jpg: 416x416 1 manga, 33.2ms\n",
      "image 54/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_60_jpg.rf.64d4475ae97709afa737a940cbd80093.jpg: 416x416 1 manga, 31.5ms\n",
      "image 55/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_61_jpg.rf.402eb61b2a06c2d4a3b282da6464d742.jpg: 416x416 1 manga, 34.4ms\n",
      "image 56/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_65_jpg.rf.0c9b4fea79ec7ba162518c56b8a7caf1.jpg: 416x416 1 manga, 33.8ms\n",
      "image 57/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_6_jpg.rf.5c0b64267b893de588a8d01002a10719.jpg: 416x416 1 manga, 32.9ms\n",
      "image 58/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_70_jpg.rf.a1107241d33a9df6b6cb2ada908ec85a.jpg: 416x416 1 manga, 29.2ms\n",
      "image 59/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_71_jpg.rf.afe12aa2eb4386b2bf11316796df986f.jpg: 416x416 1 manga, 33.7ms\n",
      "image 60/60 /home/asf/CESAR/dl-fruit-classification/yolov5/Fruit-Types-1/test/images/manga_7_jpg.rf.96a33a15e9e456caffd9f5dc6905aff9.jpg: 416x416 1 manga, 31.7ms\n",
      "Speed: 0.2ms pre-process, 33.0ms inference, 0.5ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf335b-a23b-45bf-bf80-e0ca02aa8450",
   "metadata": {},
   "source": [
    "### ConclusÃ£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e958c2f-a616-4023-a7e7-d67e708b8c6f",
   "metadata": {},
   "source": [
    "O modelo treinado conseguiu uma precisÃ£o de **99,50 %**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659be0d-9c11-4094-8a30-7102d4e607b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
